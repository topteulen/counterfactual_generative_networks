Namespace(dataset='wildlife_MNIST_counterfactual', batch_size=64, epochs=3, lr=1.0, gamma=0.7, log_interval=100, model='C8SteerableCNN')

Number of trainable parameters: 2068298

Train Epoch: 1 [0/100000 (0%)]	Loss: 2.403638
Train Epoch: 1 [6400/100000 (6%)]	Loss: 0.551583
Train Epoch: 1 [12800/100000 (13%)]	Loss: 0.282780
Train Epoch: 1 [19200/100000 (19%)]	Loss: 0.338110
Train Epoch: 1 [25600/100000 (26%)]	Loss: 0.114838
Train Epoch: 1 [32000/100000 (32%)]	Loss: 0.267381
Train Epoch: 1 [38400/100000 (38%)]	Loss: 0.074302
Train Epoch: 1 [44800/100000 (45%)]	Loss: 0.410449
Train Epoch: 1 [51200/100000 (51%)]	Loss: 0.078549
Train Epoch: 1 [57600/100000 (58%)]	Loss: 0.045064
Train Epoch: 1 [64000/100000 (64%)]	Loss: 0.037644
Train Epoch: 1 [70400/100000 (70%)]	Loss: 0.045615
Train Epoch: 1 [76800/100000 (77%)]	Loss: 0.038873
Train Epoch: 1 [83200/100000 (83%)]	Loss: 0.056724
Train Epoch: 1 [89600/100000 (90%)]	Loss: 0.013461
Train Epoch: 1 [96000/100000 (96%)]	Loss: 0.060282

Train set: Average loss: 0.0959, Accuracy: 92747/100000 (92.7%)


Test set test: Average loss: 14.6282, Accuracy: 4506/10000 (45.060%)

Test set test_counterfactual: Average loss: 11.4487, Accuracy: 5689/10000 (56.890%)

Test set test_counterfactual_rot: Average loss: 38.4957, Accuracy: 1756/10000 (17.560%)

Test set test_counterfactual_rot_scale: Average loss: 53.8285, Accuracy: 1548/10000 (15.480%)

Test set test_counterfactual_rot_scale_shear: Average loss: 51.5852, Accuracy: 1503/10000 (15.030%)
Train Epoch: 2 [0/100000 (0%)]	Loss: 0.013414
Train Epoch: 2 [6400/100000 (6%)]	Loss: 0.031929
Train Epoch: 2 [12800/100000 (13%)]	Loss: 0.070252
Train Epoch: 2 [19200/100000 (19%)]	Loss: 0.006851
Train Epoch: 2 [25600/100000 (26%)]	Loss: 0.038804
Train Epoch: 2 [32000/100000 (32%)]	Loss: 0.021869
Train Epoch: 2 [38400/100000 (38%)]	Loss: 0.007524
Train Epoch: 2 [44800/100000 (45%)]	Loss: 0.022896
Train Epoch: 2 [51200/100000 (51%)]	Loss: 0.071198
Train Epoch: 2 [57600/100000 (58%)]	Loss: 0.020177
Train Epoch: 2 [64000/100000 (64%)]	Loss: 0.013101
Train Epoch: 2 [70400/100000 (70%)]	Loss: 0.047117
Train Epoch: 2 [76800/100000 (77%)]	Loss: 0.072061
Train Epoch: 2 [83200/100000 (83%)]	Loss: 0.034126
Train Epoch: 2 [89600/100000 (90%)]	Loss: 0.013848
Train Epoch: 2 [96000/100000 (96%)]	Loss: 0.011424

Train set: Average loss: 0.0002, Accuracy: 98648/100000 (98.6%)


Test set test: Average loss: 27.0848, Accuracy: 3483/10000 (34.830%)

Test set test_counterfactual: Average loss: 25.7582, Accuracy: 3773/10000 (37.730%)

Test set test_counterfactual_rot: Average loss: 46.2101, Accuracy: 1404/10000 (14.040%)

Test set test_counterfactual_rot_scale: Average loss: 55.8303, Accuracy: 1288/10000 (12.880%)

Test set test_counterfactual_rot_scale_shear: Average loss: 54.0492, Accuracy: 1213/10000 (12.130%)
Train Epoch: 3 [0/100000 (0%)]	Loss: 0.011536
Train Epoch: 3 [6400/100000 (6%)]	Loss: 0.002747
Train Epoch: 3 [12800/100000 (13%)]	Loss: 0.004194
Train Epoch: 3 [19200/100000 (19%)]	Loss: 0.014784
Train Epoch: 3 [25600/100000 (26%)]	Loss: 0.012689
Train Epoch: 3 [32000/100000 (32%)]	Loss: 0.008844
Train Epoch: 3 [38400/100000 (38%)]	Loss: 0.004969
Train Epoch: 3 [44800/100000 (45%)]	Loss: 0.011384
Train Epoch: 3 [51200/100000 (51%)]	Loss: 0.011385
Train Epoch: 3 [57600/100000 (58%)]	Loss: 0.004695
Train Epoch: 3 [64000/100000 (64%)]	Loss: 0.047102
Train Epoch: 3 [70400/100000 (70%)]	Loss: 0.006529
Train Epoch: 3 [76800/100000 (77%)]	Loss: 0.037153
Train Epoch: 3 [83200/100000 (83%)]	Loss: 0.020471
Train Epoch: 3 [89600/100000 (90%)]	Loss: 0.009769
Train Epoch: 3 [96000/100000 (96%)]	Loss: 0.009300

Train set: Average loss: 0.0018, Accuracy: 99496/100000 (99.5%)


Test set test: Average loss: 15.7567, Accuracy: 2389/10000 (23.890%)

Test set test_counterfactual: Average loss: 15.8996, Accuracy: 3339/10000 (33.390%)

Test set test_counterfactual_rot: Average loss: 33.4100, Accuracy: 1254/10000 (12.540%)

Test set test_counterfactual_rot_scale: Average loss: 38.3334, Accuracy: 1240/10000 (12.400%)

Test set test_counterfactual_rot_scale_shear: Average loss: 37.2036, Accuracy: 1186/10000 (11.860%)
